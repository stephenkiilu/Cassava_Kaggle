{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "rmSMfmej29BB",
        "outputId": "81112eac-82e4-4b51-e260-29b746ff8fe8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f802b4a9-9666-4efb-b0ad-4ab964a681b5\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f802b4a9-9666-4efb-b0ad-4ab964a681b5\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"stephenkiilu\",\"key\":\"da68981283aa1159e5caf2a0d1646417\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r_b8mgucgEVY"
      },
      "outputs": [],
      "source": [
        "# create a temp directory called '.kaggle'\n",
        "!mkdir ~/.kaggle\n",
        "\n",
        "# copy the newly-uploaded file to that directory\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "\n",
        "# change permission of the file\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "e_lfuy04J523"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UtIfvfwmg81e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebf4a4d6-b5eb-481e-e940-0c86698629c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ref                                                            title                                             size  lastUpdated          downloadCount  voteCount  usabilityRating  \n",
            "-------------------------------------------------------------  -----------------------------------------------  -----  -------------------  -------------  ---------  ---------------  \n",
            "datasets/muratkokludataset/date-fruit-datasets                 Date Fruit Datasets                              408KB  2022-04-03 09:25:39            799        201  0.9375           \n",
            "datasets/piterfm/2022-ukraine-russian-war                      2022 Ukraine Russia War                            2KB  2022-04-16 14:04:28           8783        489  1.0              \n",
            "datasets/muratkokludataset/acoustic-extinguisher-fire-dataset  Acoustic Extinguisher Fire Dataset               621KB  2022-04-02 22:59:36             56        181  0.9375           \n",
            "datasets/kamilpytlak/personal-key-indicators-of-heart-disease  Personal Key Indicators of Heart Disease           3MB  2022-02-16 10:18:03          14603        310  1.0              \n",
            "datasets/muratkokludataset/pistachio-image-dataset             Pistachio Image Dataset                           27MB  2022-03-28 18:01:27             29        172  0.9375           \n",
            "datasets/muratkokludataset/rice-image-dataset                  Rice Image Dataset                               219MB  2022-04-03 02:12:00            112        168  0.875            \n",
            "datasets/muratkokludataset/pistachio-dataset                   Pistachio Dataset                                  2MB  2022-04-03 08:38:21            128        141  0.9375           \n",
            "datasets/muratkokludataset/grapevine-leaves-image-dataset      Grapevine Leaves Image Dataset                   109MB  2022-04-03 09:00:54             21        160  0.8125           \n",
            "datasets/muratkokludataset/raisin-dataset                      Raisin Dataset                                   112KB  2022-04-03 00:23:16             63        119  0.9375           \n",
            "datasets/prasertk/population-pyramid-by-country-from-19502022  Population pyramid by country from 1950-2022     461KB  2022-04-13 09:42:07            281         21  1.0              \n",
            "datasets/muhmores/spotify-top-100-songs-of-20152019            Spotify Top 100 Songs of 2010-2019               139KB  2022-04-09 06:35:36            479         16  0.8235294        \n",
            "datasets/muratkokludataset/durum-wheat-dataset                 Durum Wheat Dataset                              983MB  2022-04-03 00:02:29             20        132  0.875            \n",
            "datasets/xhlulu/cpc-codes                                      Cooperative Patent Classification Codes Meaning    5MB  2022-03-22 03:04:36            674         81  1.0              \n",
            "datasets/muratkokludataset/dry-bean-dataset                    Dry Bean Dataset                                   5MB  2022-04-02 23:19:30             40        127  0.875            \n",
            "datasets/vivek468/superstore-dataset-final                     Superstore Dataset                               550KB  2022-02-17 11:33:07          10046        191  1.0              \n",
            "datasets/rinichristy/2022-fuel-consumption-ratings             2022 Fuel Consumption Ratings                     13KB  2022-04-06 14:41:35            475         10  1.0              \n",
            "datasets/muratkokludataset/rice-msc-dataset                    Rice MSC Dataset                                 102MB  2022-04-03 01:33:52             49        118  0.875            \n",
            "datasets/muratkokludataset/pumpkin-seeds-dataset               Pumpkin Seeds Dataset                            393KB  2022-03-28 18:28:16             61        119  0.875            \n",
            "datasets/shivkumarganesh/world-happiness-report-20152022       World Happiness Report 2015-2022                  69KB  2022-04-09 20:49:07            693         30  0.9705882        \n",
            "datasets/prasertk/major-social-media-stock-prices-20122022     Major social media stock prices 2012-2022        175KB  2022-04-07 08:04:53            537         27  1.0              \n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-p3rAjzhS8n"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cxnmgu4shkHu"
      },
      "outputs": [],
      "source": [
        "!mkdir Cassava_Disease_Classification\n",
        "os.chdir('Cassava_Disease_Classification')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f90PpaYChqxP"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade pip\n",
        "!pip install kaggle==1.5.6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B2lHHzwvhvXw"
      },
      "outputs": [],
      "source": [
        "!kaggle competitions download -c ammi-2021-convnets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9IWQKEGh8wK"
      },
      "outputs": [],
      "source": [
        "!unzip ammi-2021-convnets.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ttach\n",
        "!pip install git+https://github.com/gbaydin/hypergradient-descent.git\n",
        "!pip install pretrainedmodels"
      ],
      "metadata": {
        "id": "IBAp7kdW4YeW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "081017e7-c6ae-4d55-a364-781693be0cf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ttach\n",
            "  Downloading ttach-0.0.3-py3-none-any.whl (9.8 kB)\n",
            "Installing collected packages: ttach\n",
            "Successfully installed ttach-0.0.3\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting git+https://github.com/gbaydin/hypergradient-descent.git\n",
            "  Cloning https://github.com/gbaydin/hypergradient-descent.git to /tmp/pip-req-build-vvzq9gza\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/gbaydin/hypergradient-descent.git /tmp/pip-req-build-vvzq9gza\n",
            "  Resolved https://github.com/gbaydin/hypergradient-descent.git to commit 020d6080c4cedfbc88d5cdb7a2a53f92b34c2b16\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: hypergrad\n",
            "  Building wheel for hypergrad (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hypergrad: filename=hypergrad-0.1-py3-none-any.whl size=8199 sha256=fa1df9a2f3d4f6bc30c9973e1b1dc78a316e1462ca1fb451f5fed3ccca791d1f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ktbqji7_/wheels/fa/d5/8a/dc75fcd964cc54c2d95c3989c7b3382cd31c71bf1ec7d34750\n",
            "Successfully built hypergrad\n",
            "Installing collected packages: hypergrad\n",
            "Successfully installed hypergrad-0.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting pretrainedmodels\n",
            "  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 KB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from pretrainedmodels) (1.10.0+cu111)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from pretrainedmodels) (0.11.1+cu111)\n",
            "Collecting munch\n",
            "  Downloading munch-2.5.0-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pretrainedmodels) (4.64.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from munch->pretrainedmodels) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->pretrainedmodels) (4.1.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->pretrainedmodels) (1.21.5)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->pretrainedmodels) (7.1.2)\n",
            "Building wheels for collected packages: pretrainedmodels\n",
            "  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60965 sha256=5ae733ad903c0da3e60de2aadac71adb65416be06c85feeaac6e44c6176e1483\n",
            "  Stored in directory: /root/.cache/pip/wheels/ed/27/e8/9543d42de2740d3544db96aefef63bda3f2c1761b3334f4873\n",
            "Successfully built pretrainedmodels\n",
            "Installing collected packages: munch, pretrainedmodels\n",
            "Successfully installed munch-2.5.0 pretrainedmodels-0.7.4\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4ZpVlqY1nM5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lP5Gwvl5fRrM"
      },
      "outputs": [],
      "source": [
        "#Imports\n",
        "import os\n",
        "import sys\n",
        "import glob\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "import numpy    as np\n",
        "import datetime as dt\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot   as plt\n",
        "\n",
        "from PIL               import Image\n",
        "from torch.utils.data  import Dataset\n",
        "from torch.autograd    import Variable\n",
        "from torch.optim       import lr_scheduler\n",
        "\n",
        "from torch.utils.data  import Dataset, DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torchvision       import transforms, datasets, models\n",
        "from os                import listdir, makedirs, getcwd, remove\n",
        "from os.path           import isfile, join, abspath, exists, isdir, expanduser\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from hypergrad import SGDHD, AdamHD\n",
        "\n",
        "import pretrainedmodels\n",
        "\n",
        "\n",
        "import ttach as tta\n",
        "\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(pretrainedmodels.model_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxh9wTPgrAK_",
        "outputId": "de0507d4-6399-40e9-9b41-2bb1dc06cd11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['fbresnet152', 'bninception', 'resnext101_32x4d', 'resnext101_64x4d', 'inceptionv4', 'inceptionresnetv2', 'alexnet', 'densenet121', 'densenet169', 'densenet201', 'densenet161', 'resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152', 'inceptionv3', 'squeezenet1_0', 'squeezenet1_1', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn', 'vgg19_bn', 'vgg19', 'nasnetamobile', 'nasnetalarge', 'dpn68', 'dpn68b', 'dpn92', 'dpn98', 'dpn131', 'dpn107', 'xception', 'senet154', 'se_resnet50', 'se_resnet101', 'se_resnet152', 'se_resnext50_32x4d', 'se_resnext101_32x4d', 'cafferesnet101', 'pnasnet5large', 'polynet']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v_Y0sVOAfRrQ"
      },
      "outputs": [],
      "source": [
        "data_path = \"../Cassava_Disease_Classification/\"\n",
        "train_path = join(data_path, \"train/train\")\n",
        "test_path = join(data_path,\"test/test\")\n",
        "extraimage_path = join(data_path, \"extraimages/extraimages\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NAME = \"SUBMISSION\"\n",
        "\n",
        "MODEL_NAME1 = 'resnet152' # could be fbresnet152 or inceptionresnetv2\n",
        "\n",
        "DIM_1 = 550\n",
        "DIM_2 = 224\n",
        "DIM_TEST_1 = 550\n",
        "DIM_TEST_2 = 224\n",
        "\n",
        "BATCH_SIZE = 8\n",
        "\n",
        "NUM_EPOCHS1 = 5\n",
        "\n",
        "random_seed = 42\n",
        "shuffle_dataset = True\n",
        "validation_split = .1"
      ],
      "metadata": {
        "id": "dVZm4xrm0vjE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Yyc6JaKfRrR"
      },
      "outputs": [],
      "source": [
        "# Transformations for both the training and testing data\n",
        "mean=[0.485, 0.456, 0.406]\n",
        "std=[0.229, 0.224, 0.225]\n",
        "\n",
        "# Do data transforms here, Try many others\n",
        "train_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
        "                                       transforms.Resize(DIM_1),\n",
        "                                       transforms.RandomCrop(DIM_2),\n",
        "                                       transforms.RandomHorizontalFlip(0.3),\n",
        "                                       transforms.RandomVerticalFlip(0.3),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.RandomErasing(0.1),\n",
        "                                       transforms.Normalize(mean=mean, std=std)])\n",
        "\n",
        "test_transforms = transforms.Compose([ transforms.Resize(DIM_TEST_1),\n",
        "                                      transforms.CenterCrop(DIM_TEST_1),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize(mean=mean, std=std)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DfVZO0nGfRrR"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "class CassavaDataset(Dataset):\n",
        "    def __init__(self, path, dim, transform=None):\n",
        "        self.classes = os.listdir(path)\n",
        "        self.path = [f\"{path}/{className}\" for className in self.classes]\n",
        "        self.file_list = [glob.glob(f\"{x}/*\") for x in self.path]\n",
        "        self.transform = transform\n",
        "        self.dim = dim\n",
        "\n",
        "        self.targets = []\n",
        "        \n",
        "\n",
        "        files = []\n",
        "        for i, className in enumerate(self.classes):\n",
        "            for fileName in self.file_list[i]:\n",
        "                files.append([i, className, fileName])\n",
        "                self.targets.append(i)\n",
        "                \n",
        "        self.file_list = files\n",
        "        files = None\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        fileName = self.file_list[idx][2]\n",
        "        classCategory = self.file_list[idx][0]\n",
        "        im = Image.open(fileName)\n",
        "        if self.transform:\n",
        "            im = self.transform(im)\n",
        "            \n",
        "        return im.view(3, self.dim, self.dim), classCategory"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CassavaTestDataset(Dataset):\n",
        "    def __init__(self, path, dim, transform=None):\n",
        "        self.classes = os.listdir(path)\n",
        "        self.path = [f\"{path}/{className}\" for className in self.classes]\n",
        "        self.file_list = [glob.glob(f\"{x}/*\") for x in self.path]\n",
        "        self.transform = transform\n",
        "        self.indices = []\n",
        "        self.dim=dim\n",
        "\n",
        "        files = []\n",
        "        for i, className in enumerate(self.classes):\n",
        "            for fileName in self.file_list[i]:\n",
        "                files.append([i, className, fileName])\n",
        "                self.indices.append(fileName.split(\"/\")[-1])\n",
        "        self.file_list = files\n",
        "        files = None\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        fileName = self.file_list[idx][2]\n",
        "        index = self.file_list[idx][2]\n",
        "        im = Image.open(fileName)\n",
        "        if self.transform:\n",
        "            im = self.transform(im)\n",
        "            \n",
        "        return im.view(3, self.dim, self.dim), index"
      ],
      "metadata": {
        "id": "xqwVUMUCQWyM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HTA4OT91fRrS"
      },
      "outputs": [],
      "source": [
        "train_data = CassavaDataset(train_path, dim=DIM_2, transform=train_transforms)\n",
        "test_data = CassavaTestDataset(test_path, dim=DIM_TEST_1, transform=test_transforms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PO-NDa8qfRrS"
      },
      "outputs": [],
      "source": [
        "validation_split = .2\n",
        "shuffle_dataset = True\n",
        "random_seed= 42\n",
        "\n",
        "# Creating data indices for training and validation splits:\n",
        "dataset_size = len(train_data)\n",
        "indices = list(range(dataset_size))\n",
        "split = int(np.floor(validation_split * dataset_size))\n",
        "\n",
        "if shuffle_dataset :\n",
        "    np.random.seed(random_seed)\n",
        "    np.random.shuffle(indices)\n",
        "\n",
        "train_indices, val_indices = indices[split:], indices[:split]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GJDpeutcfRrT"
      },
      "outputs": [],
      "source": [
        "# Creating PT data samplers and loaders:\n",
        "train_sampler = SubsetRandomSampler(train_indices)\n",
        "valid_sampler = SubsetRandomSampler(val_indices)\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=BATCH_SIZE,\n",
        "                                             sampler=train_sampler)\n",
        "valid_loader = torch.utils.data.DataLoader(train_data, batch_size=BATCH_SIZE,\n",
        "                                             sampler=valid_sampler)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "d1EJ3h8HSkq5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LRMj7UK-fRrU"
      },
      "outputs": [],
      "source": [
        "# Device configuration\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, data_loader):\n",
        "    \"\"\"Measures the accuracy of a model on a data set.\"\"\" \n",
        "    # Make sure the model is in evaluation mode.\n",
        "    model.eval()\n",
        "    # We do not need to maintain intermediate activations while testing.\n",
        "    accs = []\n",
        "    with torch.no_grad():\n",
        "        \n",
        "        # Loop over test data.\n",
        "        for features, target in data_loader:\n",
        "          \n",
        "            # Forward pass.\n",
        "            output = model(features.to(device))\n",
        "            \n",
        "            # Get the label corresponding to the highest predicted probability.\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            \n",
        "            # Count number of correct predictions.\n",
        "            correct = pred.cpu().eq(target.view_as(pred)).sum().item()\n",
        "            total = pred.shape[0]\n",
        "            accs.append(correct/total)\n",
        "\n",
        "    # Print test accuracy.\n",
        "    percent = 100. * np.mean(accs)\n",
        "    st = np.std(accs)\n",
        "    return percent, st"
      ],
      "metadata": {
        "id": "XBATqKpTDhkm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, criterion, data_loader, test_data_loader, optimizer, num_epochs, filename):\n",
        "    \"\"\"Simple training loop for a PyTorch model.\"\"\" \n",
        "    \n",
        "    # Make sure model is in training mode.\n",
        "    model.train()\n",
        "    \n",
        "    # Move model to the device (CPU or GPU).\n",
        "    model.to(device)\n",
        "    \n",
        "    # Exponential moving average of the loss.\n",
        "    ema_loss = None\n",
        "    \n",
        "    best_acc = 0\n",
        "\n",
        "    print('----- Training Loop -----')\n",
        "    # Loop over epochs.\n",
        "    for epoch in range(num_epochs):\n",
        "        \n",
        "        # Loop over data.\n",
        "        for batch_idx, (features, target) in enumerate(data_loader):\n",
        "\n",
        "            # Forward pass.\n",
        "            output = model(features.to(device))\n",
        "            loss = criterion(output.to(device), target.to(device))\n",
        "\n",
        "            # Backward pass.\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # NOTE: It is important to call .item() on the loss before summing.\n",
        "            if ema_loss is None:\n",
        "                ema_loss = loss.item()\n",
        "            else:\n",
        "                ema_loss += (loss.item() - ema_loss) * 0.01 \n",
        "\n",
        "        # Print out progress the end of epoch.\n",
        "        print('----- Model Evaluation -----')\n",
        "        print('Epoch: {}/{} \\tTrain Loss: {:.6f}'.format(epoch+1,num_epochs, ema_loss))\n",
        "        train_a, train_st = test(model,data_loader)\n",
        "        test_a, test_st = test(model,test_data_loader)\n",
        "        print(f'Train accuracy: ({train_a:.2f}%) with std:({train_st:.2f})')\n",
        "        print(f'Test accuracy: ({test_a:.2f}%) with std:({test_st:.2f})')\n",
        "        if test_a > best_acc:\n",
        "            best_acc = test_a\n",
        "            torch.save(model.state_dict(), filename+\".pth\")\n",
        "            \n",
        "    checkpoint = torch.load(filename+\".pth\")\n",
        "    model.load_state_dict(checkpoint)\n",
        "    print(\"------\")\n",
        "    test_a, test_st = test(model,test_data_loader)\n",
        "    print(f'Final test accuracy: ({test_a:.2f}%) with std:({test_st:.2f})')\n",
        "    \n",
        "    return model"
      ],
      "metadata": {
        "id": "UJ1_N7Ve_D4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_predictions(model,data_loader):\n",
        "    model.eval()\n",
        "    preds=[]\n",
        "    idx=[]\n",
        "\n",
        "    print('----- MAKING PREDICTIONS -----')\n",
        "    # We do not need to maintain intermediate activations while testing.\n",
        "    with torch.no_grad():\n",
        "        \n",
        "        # Loop over test data.\n",
        "        for features, indices in data_loader:\n",
        "            \n",
        "            # Forward pass.\n",
        "            output = model(features.to(device))\n",
        "            \n",
        "            # Get the label corresponding to the highest predicted probability.\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            for p,ind in zip(pred,indices):\n",
        "                idx.append(ind)\n",
        "                preds.append(p.item())\n",
        "\n",
        "    return preds,idx\n",
        "\n",
        "def map_to_classes(n):\n",
        "    return train_data.classes[n]"
      ],
      "metadata": {
        "id": "QpcYlWi5_AtO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def test(model, data_loader) :\n",
        "#   ####Measures the accuracy of a model on a data set.\"''''\n",
        "#   # Make sure the model is in evaluation mode.\n",
        "#   model.eval()\n",
        "#   correct=0\n",
        "#   total =0\n",
        "#   print('-----Model Evaluation-----')\n",
        "#   # We do not need to maintain intermediate activations while testing.\n",
        "#   with torch.no_grad():\n",
        "#   # Loop over test data.\n",
        "#     for features, target in data_loader:\n",
        "#       # Forward pass.\n",
        "#       output = model (features.to(device))\n",
        "#       # Get the label corresponding to the highest predicted probability.\n",
        "#       pred = output.argmax(dim=1, keepdim=True)\n",
        "#       # Count number of correct predictions.\n",
        "#       total +=len(features)\n",
        "#       correct += pred.cpu().eq(target.view_as (pred)) .sum().item()\n",
        "#   # Print test accuracy.\n",
        "#   percent = 100. * correct / total\n",
        "#   print(f'Test accuracy: {correct} / {total} ({percent:.0f}%) ')\n",
        "#   torch.save (model.state_dict(),'model.ckpt')\n",
        "#   return percent"
      ],
      "metadata": {
        "id": "gVXkszuIBJrr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "fNQQLJEOUOFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from torchvision.models.efficientnet import efficientnet_b0\n",
        "# efficientnet = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_efficientnet_b0', pretrained=True)\n",
        "# efficientnet.get_parameter"
      ],
      "metadata": {
        "id": "lwqCp3oUXakS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# resnet152 = models.vgg19(pretrained=True)\n",
        "# resnet152.get_parameter"
      ],
      "metadata": {
        "id": "pwht8N0-_-fx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_resnext(model_name):\n",
        "    model = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained='imagenet')\n",
        "    model.avg_pool = nn.AdaptiveAvgPool2d(output_size=(1, 1))\n",
        "    model.last_linear = nn.Linear(in_features=2048, out_features=5, bias=True)\n",
        "\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = AdamHD(model.parameters(), lr=1e-4, hypergrad_lr=1e-9)\n",
        "\n",
        "    return model, criterion, optimizer"
      ],
      "metadata": {
        "id": "boItN7ZK2iz3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = []"
      ],
      "metadata": {
        "id": "TfSbDnyXyku1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1, criterion, optimizer = get_resnext(MODEL_NAME1)\n",
        "\n",
        "model1 = train(model1, criterion, train_loader, valid_loader, optimizer, num_epochs=NUM_EPOCHS1, filename=\"resnext\")\n",
        "\n",
        "tta_model = tta.ClassificationTTAWrapper(model1, tta.aliases.five_crop_transform(DIM_TEST_2,DIM_TEST_2))\n",
        "predictions, _ = generate_predictions(tta_model,test_loader)\n",
        "preds.append(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_MWiSoaUygSI",
        "outputId": "631a33c5-d0c3-4c5e-fa86-89025085a9ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- Training Loop -----\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/hypergrad/adam_hd.py:82: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1050.)\n",
            "  exp_avg.mul_(beta1).add_(1 - beta1, grad)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- Model Evaluation -----\n",
            "Epoch: 1/5 \tTrain Loss: 0.830860\n",
            "Train accuracy: (75.65%) with std:(0.15)\n",
            "Test accuracy: (74.94%) with std:(0.15)\n",
            "----- Model Evaluation -----\n",
            "Epoch: 2/5 \tTrain Loss: 0.753259\n",
            "Train accuracy: (79.97%) with std:(0.14)\n",
            "Test accuracy: (78.11%) with std:(0.15)\n",
            "----- Model Evaluation -----\n",
            "Epoch: 3/5 \tTrain Loss: 0.556900\n",
            "Train accuracy: (81.03%) with std:(0.14)\n",
            "Test accuracy: (79.05%) with std:(0.13)\n",
            "----- Model Evaluation -----\n",
            "Epoch: 4/5 \tTrain Loss: 0.602112\n",
            "Train accuracy: (81.44%) with std:(0.14)\n",
            "Test accuracy: (81.60%) with std:(0.15)\n",
            "----- Model Evaluation -----\n",
            "Epoch: 5/5 \tTrain Loss: 0.520158\n",
            "Train accuracy: (83.42%) with std:(0.14)\n",
            "Test accuracy: (81.69%) with std:(0.14)\n",
            "------\n",
            "Final test accuracy: (83.27%) with std:(0.11)\n",
            "----- MAKING PREDICTIONS -----\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_predictions = np.mean(preds,axis=0)\n",
        "final_predictions.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztCPCmT6GYx8",
        "outputId": "a675d776-e2b1-4730-8b17-ff92a9147da2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3774,)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ss = pd.DataFrame({\n",
        "    \"Category\": final_predictions,\n",
        "    \"Id\": test_data.indices\n",
        "})\n",
        "ss.head()"
      ],
      "metadata": {
        "id": "XL7gsjJyxkPX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "6a14eb92-45f5-485b-84ab-b3bfc82cacc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Category                 Id\n",
              "0       2.0  test-img-3031.jpg\n",
              "1       2.0  test-img-3288.jpg\n",
              "2       2.0  test-img-2448.jpg\n",
              "3       2.0  test-img-3751.jpg\n",
              "4       2.0  test-img-2902.jpg"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-01661b53-dabf-43fe-9931-3269f27cb5f5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Category</th>\n",
              "      <th>Id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.0</td>\n",
              "      <td>test-img-3031.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.0</td>\n",
              "      <td>test-img-3288.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.0</td>\n",
              "      <td>test-img-2448.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.0</td>\n",
              "      <td>test-img-3751.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0</td>\n",
              "      <td>test-img-2902.jpg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-01661b53-dabf-43fe-9931-3269f27cb5f5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-01661b53-dabf-43fe-9931-3269f27cb5f5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-01661b53-dabf-43fe-9931-3269f27cb5f5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "ss[\"Category\"] = predictions\n",
        "ss[\"Category\"] = ss[\"Category\"].apply(map_to_classes)\n",
        "ss.head()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "MGwlirgyPh7W",
        "outputId": "9c547ee3-1529-4868-f9fa-2e79f03519b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Category                 Id\n",
              "0      cmd  test-img-3031.jpg\n",
              "1      cmd  test-img-3288.jpg\n",
              "2      cmd  test-img-2448.jpg\n",
              "3      cmd  test-img-3751.jpg\n",
              "4      cmd  test-img-2902.jpg"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cde39a09-9542-4e8e-8b3a-5398324a02dc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Category</th>\n",
              "      <th>Id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cmd</td>\n",
              "      <td>test-img-3031.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>cmd</td>\n",
              "      <td>test-img-3288.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>cmd</td>\n",
              "      <td>test-img-2448.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>cmd</td>\n",
              "      <td>test-img-3751.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>cmd</td>\n",
              "      <td>test-img-2902.jpg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cde39a09-9542-4e8e-8b3a-5398324a02dc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cde39a09-9542-4e8e-8b3a-5398324a02dc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cde39a09-9542-4e8e-8b3a-5398324a02dc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "ss.to_csv(\"submit15.csv\",index=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "V9G4kjt9P2kX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "fbJMFORERB4J"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "stephen_kiilu_AMMI_project_file-Kaggle",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 585.822379,
      "end_time": "2021-03-29T12:00:26.314136",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2021-03-29T11:50:40.491757",
      "version": "2.2.2"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}